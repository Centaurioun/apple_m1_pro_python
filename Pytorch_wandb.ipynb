{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a2c81a5-7d6c-46e4-86de-e5063688522e",
   "metadata": {},
   "source": [
    "# Pytorch CIFAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e535cea-7623-402a-99f3-39e44ffd0ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "import wandb\n",
    "\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from fastprogress import progress_bar, master_bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f7da763-c289-4a89-9669-efdd0819a49b",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT = \"apple_m1_pro\"\n",
    "ENTITY = \"tcapelle\"\n",
    "GROUP = 'pytorch'\n",
    "\n",
    "# Ensure deterministic behavior\n",
    "torch.backends.cudnn.deterministic = True\n",
    "random.seed(hash(\"setting random seeds\") % 2 ** 32 - 1)\n",
    "np.random.seed(hash(\"improves reproducibility\") % 2 ** 32 - 1)\n",
    "torch.manual_seed(hash(\"by removing stochasticity\") % 2 ** 32 - 1)\n",
    "torch.cuda.manual_seed_all(hash(\"so runs are repeatable\") % 2 ** 32 - 1)\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d5b78a4-0a96-4deb-b3c1-557dcccdf205",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mtcapelle\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/tcapelle/apple_m1_pro/runs/22k52lbj\" target=\"_blank\">quiet-universe-1</a></strong> to <a href=\"https://wandb.ai/tcapelle/apple_m1_pro\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.login()\n",
    "\n",
    "run = wandb.init(project=PROJECT,\n",
    "                 entity=ENTITY,\n",
    "                 group=GROUP, \n",
    "                 config = {\n",
    "                    \"lr\": 0.005,\n",
    "                    \"epochs\": 5,\n",
    "                    \"batch_size\": 128,\n",
    "                    \"loss_function\": \"CrossEntropyLoss\",\n",
    "                    \"architecture\": \"cnn\",\n",
    "                    \"dataset\": \"CIFAR-10\",\n",
    "                })\n",
    "config = wandb.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d9af67f8-23f9-40f5-83e0-a0be7aea1a76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(), \n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]\n",
    ")\n",
    "\n",
    "def get_data(train=True, sample=True):\n",
    "    ds = torchvision.datasets.CIFAR10(\n",
    "        root=\"./data\", train=train, download=True, transform=transform)\n",
    "\n",
    "    if sample and train:\n",
    "        ds.data = ds.data[::5]\n",
    "\n",
    "    loader = torch.utils.data.DataLoader(\n",
    "        ds, batch_size=config.batch_size*(2-train), shuffle=train, num_workers=2)\n",
    "    return loader\n",
    "\n",
    "train_loader, test_loader = get_data(True), get_data(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4fd1bf27-7613-44f2-92fa-66aa2cd70fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0f10825e-245b-4a23-b69b-4bf2e72d587e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([128, 3, 32, 32]), len loader: 391\n"
     ]
    }
   ],
   "source": [
    "x, y = next(iter(train_loader))\n",
    "print(f'Input shape: {x.shape}, len loader: {len(train_loader)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ed5d24b5-d6e0-4279-ab6e-c3548f7ea18a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 3, 32, 32])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c8e25ec9-bbba-412e-937e-ba6a724ac13d",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6b0f369b-8bfe-48b0-8fb8-517ab4e9a445",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7ef26eaa-8b85-46b2-b28b-9f1e3e247d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Conv2d(3, 32, 3),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(32, 32, 3),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(2),\n",
    "    nn.Conv2d(32, 32, 3),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(32, 32, 3),\n",
    "    nn.AdaptiveAvgPool2d(1),\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(32, 128),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(128, 32),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(32, len(classes))\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5c25b4d8-2a86-454d-9957-33cff84a0fc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.3079, device='cuda:0', grad_fn=<NllLossBackward>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "criterion(model(x.to(device)), y.to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "786f91da-e662-42bb-a65c-2797dd57f511",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Learner:\n",
    "    \"A Wrapper around model and data\"\n",
    "    def __init__(self, train_loader, test_loader, model, criterion):\n",
    "        self.train_loader = train_loader\n",
    "        self.test_loader = test_loader\n",
    "        self.model = model.to(device)\n",
    "        self.criterion = criterion\n",
    "        self.mb = None\n",
    "        self.batch_ct = 0\n",
    "        self.example_ct = 0\n",
    "        \n",
    "        \n",
    "    def one_batch_train(self, images, labels):\n",
    "        \"Do one batch train\"\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        self.optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass ➡\n",
    "        outputs = self.model(images)\n",
    "        loss = self.criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass ⬅\n",
    "        loss.backward()\n",
    "\n",
    "        # Step with optimizer\n",
    "        self.optimizer.step()\n",
    "\n",
    "        return loss\n",
    "    \n",
    "    def one_epoch_train(self):\n",
    "        \"Do one epoch train\"\n",
    "        self.model.train()\n",
    "        for images, labels in progress_bar(self.train_loader, parent=self.mb):\n",
    "            loss = self.one_batch_train(images, labels)\n",
    "            self.batch_ct += 1\n",
    "            self.example_ct += len(labels)\n",
    "    \n",
    "            # Report metrics every 25th batch\n",
    "            if ((self.batch_ct + 1) % 25) == 0:\n",
    "                wandb.log({\"epoch\": self.epoch, \"loss\": float(loss)})\n",
    "                \n",
    "            self.mb.child.comment = f'train_loss={loss.item():.3f}'\n",
    "    \n",
    "    \n",
    "    def one_batch_test(self, images, labels):\n",
    "        \"Do one batch test\"\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        # Forward pass ➡\n",
    "        outputs = self.model(images)\n",
    "        loss = self.criterion(outputs, labels)\n",
    "        \n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        \n",
    "        correct = (predicted == labels).sum().item()\n",
    "        \n",
    "        return loss, correct\n",
    "    \n",
    "    def one_epoch_test(self):\n",
    "        self.model.eval()\n",
    "        \n",
    "        # Run the model on some test examples\n",
    "        with torch.no_grad():\n",
    "            correct_total, loss_test = 0, 0\n",
    "            for images, labels in progress_bar(test_loader, parent=self.mb):\n",
    "                loss, correct = self.one_batch_test(images, labels)\n",
    "                correct_total += correct\n",
    "                wandb.log({\"test_loss\": float(loss)})\n",
    "        \n",
    "        wandb.log({\"test_accuracy\": correct_total / len(test_loader)})\n",
    "\n",
    "    \n",
    "    def save(self):\n",
    "        # save and log last mdoel to wandb\n",
    "        torch.save(self.model.state_dict(), 'model.pt')\n",
    "        wandb.save('model.pt')\n",
    "    \n",
    "    def fit(self, epochs, lr=config.lr):\n",
    "        \n",
    "        self.optimizer = optim.Adam(self.model.parameters(), lr=lr)\n",
    "        self.mb = master_bar(range(epochs))\n",
    "        \n",
    "        wandb.watch(self.model, self.criterion, log='all', log_freq=10)\n",
    "                          \n",
    "        for self.epoch in self.mb:\n",
    "            self.one_epoch_train()\n",
    "            self.one_epoch_test()\n",
    "        \n",
    "        self.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4f2519a8-959c-4a76-b0b1-273ab1dd9399",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = Learner(train_loader, test_loader, model, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "793ead3a-353b-4408-9436-f6b84cdd2764",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit(config.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "026250d6-90e6-4cb7-b67d-0b4c170e3b56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 1378776... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.15MB of 0.15MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▁▁▁▁▃▃▃▃▃▃▃▃▅▅▅▅▅▅▅▅▆▆▆▆▆▆▆▆████████</td></tr><tr><td>loss</td><td>█▆▆▆▅▅▅▅▅▄▄▄▄▃▃▃▄▃▃▃▃▂▄▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▁▃</td></tr><tr><td>test_accuracy</td><td>▁▃▆▇█</td></tr><tr><td>test_loss</td><td>▇▆▆▇█▇▇▇▅▆▅▆▅▆▅▅▄▃▃▃▄▄▃▃▃▂▃▂▃▃▃▂▁▂▂▂▂▃▃▁</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>4</td></tr><tr><td>loss</td><td>1.31365</td></tr><tr><td>test_accuracy</td><td>142.0</td></tr><tr><td>test_loss</td><td>1.10227</td></tr></table>\n",
       "</div></div>\n",
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">quiet-universe-1</strong>: <a href=\"https://wandb.ai/tcapelle/apple_m1_pro/runs/22k52lbj\" target=\"_blank\">https://wandb.ai/tcapelle/apple_m1_pro/runs/22k52lbj</a><br/>\n",
       "Find logs at: <code>./wandb/run-20211119_154013-22k52lbj/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be4c0cb0-e807-419e-aadd-f53e334e91a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
